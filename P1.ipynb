{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Finding Lane Lines on the Road** \n",
    "***\n",
    "This project was done as an assignment for the Udacity course \"Self-Driving Car Engineer Nanodegree\". The purpose of the code in this project is to identify the lane lines in images/videos taken from inside a moving car and transform the image/video such that the lane lines are clearly marked.\n",
    "\n",
    "<figure>\n",
    " <img src=\"test_images/solidYellowCurve.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Example of an input image </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    " <img src=\"test_images_output/solidYellowCurve-lines.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Output of the code </p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "OpenCV (cv2) is an open-source library for computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for identification of lane lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline for the identification of the lane lines consists of the following steps:\n",
    "1. Since lane lines are either white or yellow, we apply a mask to the image that will single out the white and yellow lane lines.\n",
    "2. We transform the image to the gray scale.\n",
    "3. We apply a Gaussian filter in order to get rid of noise on the image.\n",
    "4. We transform the image using Canny Edge detection. By taking the gradient of the pixels in the image this algorithm allows to detect edges in the image.\n",
    "5. We mask all the pixels in the image outside our region of interest, a trapezoid on the bottom half of the image, where the lane lines must be.\n",
    "6. Using the Hough transform we detect the lines in the image.\n",
    "7. In order to mark the lines on the image/video, we do the following:\n",
    "  1. We separate the line segments detected by the Hough algorithm into those that belong to the left lane line and those that belong to the right lane line.\n",
    "  2. We fit a polynomial y = mx + b to the points belonging to the left line segments and another polynomial to the right line segments.\n",
    "  3. For videos, in order to avoid flickering, we average the slope m and the y-intercept b over several frames.\n",
    "  4. Using the polynomials we draw the left and right lines on the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are needed for the pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_color(image, lower, upper):\n",
    "    \n",
    "    #Transform input image to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    #Create the mask (pixel values must be in between the lower and upper boundaries)\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    #Apply mask to the input image \n",
    "    res = cv2.bitwise_and(image, image, mask = mask)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    (assuming your grayscaled image is called 'gray')\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking of pixels outside the region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count #declare tuple with value 255 and length channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    \n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Hough lines and drawing them on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap, vertices, mLeft, bLeft, mRight, bRight, \\\n",
    "                avgFrames):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    #Using Hough transform detect the lines in the image\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, \\\n",
    "                            maxLineGap=max_line_gap)\n",
    "    #Initialize the line image as an array of zeros\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    #Draw the lines on the input image\n",
    "    draw_lines(line_img, lines, vertices, mLeft, bLeft, mRight, bRight, avgFrames)\n",
    "\n",
    "    return line_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img, lines, vertices, mLeft, bLeft, mRight, bRight, avgFrames):\n",
    "    \"\"\"\n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    \"\"\"\n",
    "    #separate the line segments detected with the Hough algorithm into left and right\n",
    "    lls_x, lls_y, rls_x, rls_y = seperate_line_segments(lines)\n",
    "    #fit a line to the left line segments\n",
    "    fit_line(img, lls_x, lls_y, mLeft, bLeft, avgFrames, 0, vertices[0][1][0])\n",
    "    #fit a line to the right line segments\n",
    "    fit_line(img, rls_x, rls_y, mRight, bRight, avgFrames, vertices[0][2][0], img.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_line_segments(lines):\n",
    "    \n",
    "    #Initialize arrays...\n",
    "    #...x-values of left line segments\n",
    "    left_line_segments_x = []\n",
    "    #...y-values of left line segments\n",
    "    left_line_segments_y = []\n",
    "    #...x-values of right line segments\n",
    "    right_line_segments_x = []\n",
    "    #...y-values of right line segments\n",
    "    right_line_segments_y = []\n",
    "    \n",
    "    #check if lines were found by the Hough algorithm\n",
    "    if lines is not None:\n",
    "        #loop over line segments in the output of the Hough algorithm\n",
    "        for line in lines:\n",
    "            #each line segment consists of two points that define the line, get their coordinates\n",
    "            x1 = line[0][0]\n",
    "            x2 = line[0][2]\n",
    "            y1 = line[0][1]\n",
    "            y2 = line[0][3]\n",
    "            #Calculate the slope of the line segment\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            #If the slope is negative the line segment belongs to the left line (the origin is in the upper left corner)\n",
    "            if slope < 0 :\n",
    "                left_line_segments_x.append(x1)\n",
    "                left_line_segments_x.append(x2)\n",
    "                left_line_segments_y.append(y1)\n",
    "                left_line_segments_y.append(y2)\n",
    "            #If the slope is positive, the line segment belongs to the right line\n",
    "            else :\n",
    "                right_line_segments_x.append(x1)\n",
    "                right_line_segments_x.append(x2)\n",
    "                right_line_segments_y.append(y1)\n",
    "                right_line_segments_y.append(y2)\n",
    "            \n",
    "    return left_line_segments_x, left_line_segments_y, right_line_segments_x, right_line_segments_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_line(img, ls_x, ls_y, m, b, avgFrames, x0, x1, color=[255, 0, 0], thickness=8):    \n",
    "\n",
    "    #check if the arrays of the x- and y-coordintes of the line segments are unempty\n",
    "    if ((len(ls_x)>0) and (len(ls_y)>0)):\n",
    "        #fit a polynomial y = mx + b to the points of the line segments\n",
    "        line = np.polyfit(ls_x, ls_y, 1)\n",
    "        #add the slope to the array of slopes\n",
    "        m.append(line[0])\n",
    "        #add the y-intercept to the array of y-intercepts\n",
    "        b.append(line[1])\n",
    "    \n",
    "    #if the length of the m-array is greater the number of frames we want to average over, remove the first\n",
    "    #element in the array\n",
    "    if (len(m)>avgFrames) :\n",
    "        m.pop(0)\n",
    "    \n",
    "    #if the m-array is not empty, average over it, else set m to zero\n",
    "    if (m):\n",
    "        m_av = np.average(m)\n",
    "    else:\n",
    "        m_av = 0\n",
    "      \n",
    "    #if the length of the b-array is greater the number of frames we want to average over, remove the first\n",
    "    #element in the array    \n",
    "    if (len(b)>avgFrames):\n",
    "        b.pop(0)\n",
    "    \n",
    "    #if the b-array is not empty, average over it, else set b to zero\n",
    "    if (b):\n",
    "        b_av = np.average(b)\n",
    "    else:\n",
    "        b_av = 0\n",
    "    \n",
    "    #make a function with the average values of m and b\n",
    "    f_line = np.poly1d([m_av, b_av])\n",
    "     \n",
    "    #for the x-values of the points at the beginning and the end of the line we want to draw, calculate the y-values\n",
    "    #round and cast them to integer values\n",
    "    p1 = (x0, int(round(f_line(x0))))\n",
    "    p2 = (x1, int(round(f_line(x1))))\n",
    "    \n",
    "    #draw the lines on the image\n",
    "    cv2.line(img, p1, p2, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + γ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes an input image as well as the arrays of the slopes and y-intercepts of the left and right lines \n",
    "of the previous frames and returns an image with the lane lines detected \n",
    "\n",
    "'''\n",
    "def line_detection(input_image, mLeft, bLeft, mRight, bRight):\n",
    "    \n",
    "    #lower and upper bounds for the color masking\n",
    "    lower = np.array([0,0,230])\n",
    "    upper = np.array([179,255,255])\n",
    "    \n",
    "    #color masking\n",
    "    color_masked_image = mask_color(input_image, lower, upper)\n",
    "    \n",
    "    #transform image to gray scale\n",
    "    gray_image = grayscale(color_masked_image)\n",
    "\n",
    "    #to remove noise apply Gaussian smoothing to the image\n",
    "    kernel_size = 15\n",
    "    blurred_image = gaussian_blur(gray_image, kernel_size)\n",
    "\n",
    "    #apply Canny edge detection\n",
    "    low_threshold = 50\n",
    "    high_threshold = 140\n",
    "    canny_image = canny(blurred_image, low_threshold, high_threshold)\n",
    "\n",
    "    #mask pixels outside region of interest\n",
    "    \n",
    "    #define vertices of region of interest\n",
    "    ysize = canny_image.shape[0]\n",
    "    xsize = canny_image.shape[1]\n",
    "    \n",
    "    vertices = np.array([[(int(round(0.1*xsize)), ysize),\\\n",
    "                        (int(round(0.45*xsize)), int(round(0.55*ysize))),\\\n",
    "                        (int(round(0.55*xsize)), int(round(0.55*ysize))),\\\n",
    "                        (int(round(0.9*xsize)), ysize)]],\\\n",
    "                        dtype=np.int32)\n",
    "    \n",
    "    #apply mask to the image\n",
    "    masked_image = region_of_interest(canny_image, vertices)\n",
    "    \n",
    "    #Run Hough transform on Canny edge detected image\n",
    "\n",
    "    #define parameters of Hough transform\n",
    "    rho = 1 #this is the distance resolution of the accumulator in pixels\n",
    "    theta = np.pi/180 #this is the angular resolution of the accumulator in pixels\n",
    "    threshold = 7 #Accumulator threshold parameter. Only those lines are returned that get enough votes (>threshold)\n",
    "    min_line_length = 25 #Minimum line length. Line segments shorter than that are rejected.\n",
    "    max_line_gap = 1 #Maximum allowed gap in between points considered to be on the same line.\n",
    "    avgFrames = 30 #number of frames to average lines over for videos\n",
    "    \n",
    "    line_image = hough_lines(masked_image, rho, theta, threshold, min_line_length, max_line_gap, vertices, \\\n",
    "                            mLeft, bLeft, mRight, bRight, avgFrames)\n",
    "\n",
    "    #Overlay the image of the lines and the input image\n",
    "    result_image = weighted_img(line_image, input_image)\n",
    "    \n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import images from the test_images folder, run the code on them and save them to the test_images_output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filenames_test_images = os.listdir(\"test_images/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_line_image(input_file_name):\n",
    "    \n",
    "    #read image from file\n",
    "    input_image = mpimg.imread(os.path.join(\"test_images\", input_file_name))\n",
    "    \n",
    "    #initialize the arrays for the slopes and y-intercepts of the left and right lines\n",
    "    mLeft = []\n",
    "    bLeft = []\n",
    "    mRight = []\n",
    "    bRight = []\n",
    "    \n",
    "    #Detect lane lines and draw them on the image\n",
    "    result_image = line_detection(input_image, mLeft, bLeft, mRight, bRight)\n",
    "    \n",
    "    #check if output folder exists, if not create it\n",
    "    if not os.path.exists(\"test_images_output\"):\n",
    "        os.mkdir(\"test_images_output\")\n",
    "        \n",
    "    #get filename of result image\n",
    "    (head, tail) = os.path.split(input_file_name)\n",
    "    (root, ext) = os.path.splitext(tail)\n",
    "    result_filename = os.path.join(\"test_images_output\", root + \"-lines\" + ext)\n",
    "    \n",
    "    #save the result image\n",
    "    mpimg.imsave(result_filename, result_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name in filenames_test_images:\n",
    "    save_line_image(name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \n",
    "    return line_detection(image, mLeft, bLeft, mRight, bRight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the one with the solid white lane on the right first ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:06<00:00, 32.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "CPU times: user 4.24 s, sys: 404 ms, total: 4.64 s\n",
      "Wall time: 7.89 s\n"
     ]
    }
   ],
   "source": [
    "#get video file name\n",
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "\n",
    "#initialize the arrays\n",
    "mLeft = []\n",
    "bLeft = []\n",
    "mRight = []\n",
    "bRight = []\n",
    "\n",
    "#read in video\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "\n",
    "#process the frames with the lane detection pipeline\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "\n",
    "#write video to file\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the video inline, or if you prefer find the video in your filesystem (should be in the same directory) and play it in your video player of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the one with the solid yellow lane on the left. This one's more tricky!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:20<00:00, 32.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidYellowLeft.mp4 \n",
      "\n",
      "CPU times: user 13 s, sys: 1.49 s, total: 14.5 s\n",
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "\n",
    "mLeft = []\n",
    "bLeft = []\n",
    "mRight = []\n",
    "bRight = []\n",
    "\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeft.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The most challenging one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/challenge.mp4\n",
      "[MoviePy] Writing video test_videos_output/challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:15<00:00, 15.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/challenge.mp4 \n",
      "\n",
      "CPU times: user 8.18 s, sys: 1.12 s, total: 9.3 s\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "challenge_output = 'test_videos_output/challenge.mp4'\n",
    "\n",
    "mLeft = []\n",
    "bLeft = []\n",
    "mRight = []\n",
    "bRight = []\n",
    "\n",
    "clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "challenge_clip = clip3.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:computer_vision_env] *",
   "language": "python",
   "name": "conda-env-computer_vision_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
